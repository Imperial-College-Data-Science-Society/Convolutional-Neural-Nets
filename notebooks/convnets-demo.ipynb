{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "from skimage.io import imread, imshow\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def zero_pad(X, pad):\n",
    "    return np.pad(X, ((pad, pad), (pad, pad), (0, 0)), 'constant')\n",
    "\n",
    "def load_data():\n",
    "\n",
    "    with tarfile.open('../data/data.tar.gz', 'r') as f:\n",
    "        f.extractall()\n",
    "\n",
    "    df_train = pd.read_csv('fashion_mnist_train.csv')\n",
    "    df_test = pd.read_csv('fashion_mnist_test.csv')\n",
    "\n",
    "    x_train = df_train.drop('label', axis=1).as_matrix().astype(np.uint8)\n",
    "    y_train = df_train['label'].as_matrix().astype(np.uint8)\n",
    "    x_test = df_test.drop('label', axis=1).as_matrix().astype(np.uint8)\n",
    "    y_test = df_test['label'].as_matrix().astype(np.uint8)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "img = imread('./logo.png') # the test image we will be using\n",
    "kernel = np.array([[1, 0, -1],\n",
    "                   [2, 0, -2],\n",
    "                   [1, 0, -1]])\n",
    "kernel = np.stack([kernel]*3, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural net building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(X, W):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolved = conv2d(img, kernel)\n",
    "imshow(convolved, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding and strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padding** and **stride** determine the conv layer output size.   \n",
    "\n",
    "'same' padding means that the output will have the same spatial dimensions as the input. 'valid' padding is equivalent to no padding, i.e. the output will be smaller than the input.   \n",
    "\n",
    "Stride determines by how much the kernel is moved between feature computations (by how many pixels we 'slide' it). \n",
    "\n",
    "In practice, we usually use 'same' padding and stride 1 for the convolutional layers - output has the same spatial dimensions as the input. However, those parameters are important in *pooling layers* (see below).  \n",
    "\n",
    "Read [this guide](https://arxiv.org/pdf/1603.07285.pdf) for an in-depth look at convolution arithmetics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_output_shape(input_shape, kernel_size, pad, stride):\n",
    "    return ((input_shape[0] - kernel_size + 2 * pad) // stride + 1,\n",
    "            (input_shape[1] - kernel_size + 2 * pad) // stride + 1)\n",
    "\n",
    "def conv2d_padding(X, W, padding='same', stride=1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_1 = conv2d_padding(img, kernel)\n",
    "valid_2 = conv2d_padding(img, kernel, 'valid', 2)\n",
    "same_1.shape, valid_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(X, window_size, padding='valid', stride=2):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled = max_pool(img, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(X, p):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((1, 10))\n",
    "imshow(x > 0, cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(dropout(x, .5) > 0, cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full network implementation in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "y_train = to_categorical(y_train) # convert to one-hot encoding\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard feedforward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the training is too slow\n",
    "feedforward = load_model('../models/feedforward.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, score_ff = feedforward.evaluate(x_test, y_test, batch_size=128)\n",
    "score_ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple convnet from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the training is too slow\n",
    "convnet = load_model('../models/convnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, score_conv = convnet.evaluate(x_test, y_test, batch_size=128)\n",
    "score_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further exercises\n",
    "- There is an asymptotically faster way of doing convolutions. Implement this method (*note:* use only one channel for simplicity (i.e. no depth).   \n",
    "*Hint:* there is a transform $T$ such that $T(W * X) = T(W)T(X)$, i.e. convolution is equivalent to multiplication under the transform.\n",
    "- It can be shown that spatial convolution can be rewritten in terms of matrix multiplication. Try to implement this approach. This does not improve the asymptotical complexity. However, most modern DL libraries (including ```Tensorflow```) use this method. Why?  \n",
    "*Hint:* read (this)[http://cs231n.github.io/convolutional-networks/#conv] and investigate ```im2col```).\n",
    "- A frequently used regularization technique, in addition to dropout, is *batch normalization*. It normalizes the activations after each layer so that they follow approximately standard normal distribution. Try experimenting with it in Keras (available as ```keras.layers.BatchNormalization```). How does it improve the training? Read [the original paper](https://arxiv.org/pdf/1502.03167.pdf) for further information.\n",
    "- Find an interesting classification problem (if you're out of ideas, try the classic [dogs vs cats](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data) problem) and implement *transfer learning* to solve it. Keras makes several pre-trained models available in ```keras.applications``` - try VGG16 first. Test how many training images do you need to acheive good performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
